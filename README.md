README_ifood_case_fixed.md# üöñ Case T√©cnico ‚Äî Data Architect | iFood  
### **Ingest√£o e An√°lise de Dados de T√°xis de Nova York**

---

## üéØ **Objetivo**

Esta solu√ß√£o demonstra a constru√ß√£o de um **pipeline de ingest√£o, processamento e an√°lise** para os dados p√∫blicos de corridas de t√°xi de Nova York (Yellow e Green Taxis), referente ao per√≠odo **janeiro a maio de 2023**, aplicando o padr√£o **Lakehouse Architecture** no ambiente **Databricks / Unity Catalog**.

---

## üß© **Arquitetura Geral da Solu√ß√£o**

Abaixo um diagrama simplificado (em texto) da arquitetura para garantir compatibilidade com a visualiza√ß√£o do GitHub:

```
[Download de Dados P√∫blicos] --> [Volume no Unity Catalog] --> [Processamento e Padroniza√ß√£o - PySpark]
      --> [Tabelas Delta Lake (Governadas)] --> [Consultas SQL Anal√≠ticas]
```

---

## 1Ô∏è‚É£ **Ingest√£o e Armazenamento**  
üìÇ Arquivo: `src/ingestion-file-taxi-nyc.py`

### üß≠ **Resumo Geral**

O script automatiza o **download dos arquivos p√∫blicos de viagens de t√°xi de Nova York** diretamente do **CDN oficial da NYC TLC (Taxi and Limousine Commission)** e os armazena em um **Volume do Unity Catalog** no Databricks.

> üí° Foi desenvolvido para ser executado **dentro de um notebook Databricks**, pois utiliza `dbutils.fs` e caminhos `/Volumes/...`.

---

### ‚öôÔ∏è **Etapas Principais**

#### 1. Importa√ß√£o e Configura√ß√£o
- Bibliotecas: `requests`, `os`, `dbutils`
- Configura√ß√µes:
  - `CATALOG`, `SCHEMA`, `VOLUME_NAME`: destino no Unity Catalog  
  - `BASE_URL`: origem dos arquivos  
  - `FILE_TYPES`: tipos de t√°xi (`yellow`, `green`)  
  - `YEAR` e `MONTHS`: per√≠odo de ingest√£o (ex: jan‚Äìmai/2023)

#### 2. Cria√ß√£o de Diret√≥rio
Cria o diret√≥rio no volume com:
```python
dbutils.fs.mkdirs(UC_PATH)
```
Ignora erro se j√° existir.

#### 3. Download dos Arquivos
Loop duplo sobre meses e tipos (`yellow`, `green`):

```text
https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet
```

- Faz o download com `requests.get(..., stream=True)`
- Salva o arquivo diretamente no **Volume do Unity Catalog**

#### 4. Tratamento de Erros
- Captura exce√ß√µes HTTP e timeout
- Exibe logs amig√°veis no notebook

#### 5. Relat√≥rio Final
- Exibe total de arquivos baixados
- Lista o conte√∫do com:
```python
display(dbutils.fs.ls(UC_PATH))
```

---

### üß© **Resumo Funcional**

| Fun√ß√£o | Descri√ß√£o |
|--------|------------|
| `requests.get()` | Baixa os arquivos .parquet |
| `dbutils.fs.mkdirs()` | Cria diret√≥rio no volume |
| `dbutils.fs.ls()` | Lista arquivos armazenados |
| `open(..., 'wb')` | Salva o conte√∫do bin√°rio |

---

### üí° **Como Executar**

1. Rodar o script em um **notebook Databricks (Python)**.  
2. Ajustar:
   - `CATALOG`, `SCHEMA`, `VOLUME_NAME`
   - `YEAR`, `MONTHS`
3. Executar ‚Äî o processo far√° o download e salvar√° automaticamente os arquivos `.parquet`.

---

## 2Ô∏è‚É£ **Transforma√ß√£o e Carga (ETL)**  
üìÇ Arquivo: `src/ingestion-file-taxi-nyc.py`

### üß© **Resumo ‚Äî Processamento e Carga dos Dados NYC Taxi (Yellow e Green)**

Este m√≥dulo representa a camada de **Transforma√ß√£o + Load** do pipeline.  
Ele l√™ os arquivos Parquet, padroniza schemas, unifica datasets e grava tabelas **Delta** no Unity Catalog.

---

### ‚öôÔ∏è **Etapas Principais**

#### 1. Leitura dos Arquivos
Leitura via `spark.read.parquet()` dos arquivos:
```
/Volumes/ifood_test/default/nyc_taxi_data/2023/
```

- **Yellow Taxi** ‚Üí `yellow_tripdata_2023-*.parquet`
- **Green Taxi** ‚Üí `green_tripdata_2023-*.parquet`

#### 2. Padroniza√ß√£o de Schema
Define schemas consistentes via `StructType`:
- `LongType` ‚Üí IDs
- `DoubleType` ‚Üí valores
- `TimestampType` ‚Üí datas
- `StringType` ‚Üí flags

Adiciona coluna `type_data` (‚Äúyellow‚Äù ou ‚Äúgreen‚Äù).

#### 3. Uni√£o e Casting
- Alinha colunas via `unionByName`
- Cria colunas ausentes como `NULL`
- Converte tipos com `withColumn().cast()`

#### 4. Enriquecimento
Adiciona:
```python
trip_year, trip_month = year(pickup_datetime), month(pickup_datetime)
```

#### 5. Escrita no Delta Lake
Salva tabelas finais:

| Tabela | Parti√ß√µes |
|---------|-----------|
| `ifood_test.default.taxi_trip_yellow` | `trip_year`, `trip_month` |
| `ifood_test.default.taxi_trip_green` | `trip_year`, `trip_month` |

Usa:
```python
.option("replaceWhere", "trip_year = 2023 AND trip_month IN (1,2,3)")
```
para reprocessamento seletivo.

---

### üß† **Principais Recursos T√©cnicos**

| Recurso | Descri√ß√£o |
|----------|------------|
| **PySpark DataFrame API** | Transforma√ß√£o eficiente de grandes volumes |
| **Schema enforcement** | Evita inconsist√™ncias entre meses |
| **Delta Lake** | Garantia ACID e versionamento |
| **Partitioning** | Acelera consultas |
| **replaceWhere** | Substitui√ß√£o seletiva por parti√ß√£o |

---

### üßæ **Resumo Final**

Camada **T+L (Transform + Load)** respons√°vel por:
- Ler dados brutos dos volumes
- Padronizar e corrigir schemas
- Unificar dados mensais
- Persistir em **Delta Tables governadas**

---

## 3Ô∏è‚É£ **An√°lise e Consumo (SQL Analytics)**  
üìÇ Arquivo: `src/analysis_taxi_nyc.sql`

### üìä **Consultas Anal√≠ticas**

Conjunto de queries SQL em Databricks que respondem a perguntas de neg√≥cio com base nas tabelas Delta Lake do Unity Catalog.

---

### üßÆ **1. M√©dia mensal do valor total recebido (Yellow Taxi)**

**Objetivo:** Calcular a m√©dia do valor total (`total_amount`) recebido por m√™s.  
**Fonte:** `ifood_test.default.taxi_trip_yellow`

```sql
SELECT
  trip_year,
  trip_month,
  ROUND(AVG(total_amount), 2) AS average_total_amount_monthly,
  COUNT(*) AS total_trips_in_month
FROM ifood_test.default.taxi_trip_yellow
GROUP BY trip_year, trip_month
ORDER BY trip_year, trip_month;
```

üßæ **Resultado esperado:**  
Tend√™ncia mensal de faturamento m√©dio por viagem (sazonalidade e receita).

---

### üë• **2. M√©dia de passageiros por hora do dia (Yellow + Green)**

**Objetivo:** Identificar o comportamento de demanda por hora do dia (m√™s de maio).  
**Fontes:** `taxi_trip_yellow` + `taxi_trip_green`

```sql
WITH CombinedTrips AS (
  SELECT FROM_UTC_TIMESTAMP(tpep_pickup_datetime, 'America/New_York') AS pickup_datetime_ny,
         passenger_count
  FROM ifood_test.default.taxi_trip_yellow
  WHERE trip_month = 5
  UNION ALL
  SELECT FROM_UTC_TIMESTAMP(lpep_pickup_datetime, 'America/New_York') AS pickup_datetime_ny,
         passenger_count
  FROM ifood_test.default.taxi_trip_green
  WHERE trip_month = 5
)
SELECT
  HOUR(pickup_datetime_ny) AS pickup_hour_of_day,
  ROUND(AVG(passenger_count), 2) AS average_passengers_per_hour,
  COUNT(*) AS total_trips_in_hour
FROM CombinedTrips
GROUP BY pickup_hour_of_day
ORDER BY pickup_hour_of_day;
```

üßæ **Resultado esperado:**  
Perfil hor√°rio da demanda (picos, hor√°rios de rush, padr√µes de movimenta√ß√£o).

---

### üß† **Insights e Aplica√ß√µes**

| M√©trica | Objetivo de Neg√≥cio |
|----------|--------------------|
| **M√©dia mensal de total_amount** | Avaliar sazonalidade e receita m√©dia |
| **M√©dia de passageiros/hora** | Otimizar aloca√ß√£o de frota e identificar hor√°rios de pico |

---

### üíæ **Tabelas Utilizadas**

- `ifood_test.default.taxi_trip_yellow`  
- `ifood_test.default.taxi_trip_green`

---

### üß© **Ferramentas**

- Databricks SQL / Spark SQL  
- Delta Lake  
- Fun√ß√µes: `AVG`, `COUNT`, `HOUR`, `ROUND`, `FROM_UTC_TIMESTAMP`, `UNION ALL`

---

## üèÅ **Conclus√£o**

Este projeto demonstra o ciclo completo de um pipeline **Lakehouse** em Databricks:
1. **Ingest√£o** automatizada de dados p√∫blicos.  
2. **Transforma√ß√£o** e padroniza√ß√£o em Delta Lake.  
3. **An√°lise SQL** integrada e escal√°vel.

üìò **Stack Utilizada**
- Databricks
- PySpark
- Delta Lake
- Unity Catalog
- Spark SQL

---

üë§ **Autor:** *M√°rcio Serafim*  
üìÖ *Outubro / 2025*  
üè¢ *Case T√©cnico ‚Äî iFood Data Architect*
